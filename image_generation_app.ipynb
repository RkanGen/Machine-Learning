{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbScJpM3s3vjSkwDfyid4k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RkanGen/Machine-Learning/blob/main/image_generation_app.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Image generation app ðŸŽ¨**"
      ],
      "metadata": {
        "id": "pS19bYE3uezt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_vLBTikucHT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import IPython.display\n",
        "from PIL import Image\n",
        "import base64\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "hf_api_key = os.environ['HF_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function\n",
        "import requests, json\n",
        "\n",
        "#Text-to-image endpoint\n",
        "def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_TTI_BASE']):\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
        "      \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = { \"inputs\": inputs }\n",
        "    if parameters is not None:\n",
        "        data.update({\"parameters\": parameters})\n",
        "    response = requests.request(\"POST\",\n",
        "                                ENDPOINT_URL,\n",
        "                                headers=headers,\n",
        "                                data=json.dumps(data))\n",
        "    return json.loads(response.content.decode(\"utf-8\"))"
      ],
      "metadata": {
        "id": "6i8fzboIudnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building an image generation app\n",
        "Here we are going to run `runwayml/stable-diffusion-v1-5` using the `ðŸ§¨ diffusers` library."
      ],
      "metadata": {
        "id": "wiXGbXvautrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a dog in a park\"\n",
        "\n",
        "result = get_completion(prompt)\n",
        "IPython.display.HTML(f'<img src=\"data:image/png;base64,{result}\" />')"
      ],
      "metadata": {
        "id": "usUu5QL0udkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "#A helper function to convert the PIL image to base64\n",
        "#so you can send it to the API\n",
        "def base64_to_pil(img_base64):\n",
        "    base64_decoded = base64.b64decode(img_base64)\n",
        "    byte_stream = io.BytesIO(base64_decoded)\n",
        "    pil_image = Image.open(byte_stream)\n",
        "    return pil_image\n",
        "\n",
        "def generate(prompt):\n",
        "    output = get_completion(prompt)\n",
        "    result_image = base64_to_pil(output)\n",
        "    return result_image\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=generate,\n",
        "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
        "                    outputs=[gr.Image(label=\"Result\")],\n",
        "                    title=\"Image Generation with Stable Diffusion\",\n",
        "                    description=\"Generate any image with Stable Diffusion\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\"a mecha robot in a favela\"])\n",
        "\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT1']))"
      ],
      "metadata": {
        "id": "k5r-2oBPudgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()"
      ],
      "metadata": {
        "id": "bHAPrylLuddQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Building a more advanced interface\n",
        "import gradio as gr\n",
        "\n",
        "#A helper function to convert the PIL image to base64\n",
        "# so you can send it to the API\n",
        "def base64_to_pil(img_base64):\n",
        "    base64_decoded = base64.b64decode(img_base64)\n",
        "    byte_stream = io.BytesIO(base64_decoded)\n",
        "    pil_image = Image.open(byte_stream)\n",
        "    return pil_image\n",
        "\n",
        "def generate(prompt, negative_prompt, steps, guidance, width, height):\n",
        "    params = {\n",
        "        \"negative_prompt\": negative_prompt,\n",
        "        \"num_inference_steps\": steps,\n",
        "        \"guidance_scale\": guidance,\n",
        "        \"width\": width,\n",
        "        \"height\": height\n",
        "    }\n",
        "\n",
        "    output = get_completion(prompt, params)\n",
        "    pil_image = base64_to_pil(output)\n",
        "    return pil_image"
      ],
      "metadata": {
        "id": "xogrYvaFudaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### gr.Slider()\n",
        "- You can set the `minimum`, `maximum`, and starting `value` for a `gr.Slider()`.\n",
        "- If you want the slider to increment by integer values, you can set `step=1`."
      ],
      "metadata": {
        "id": "MQXaNTKIvT9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()\n",
        "demo = gr.Interface(fn=generate,\n",
        "                    inputs=[\n",
        "                        gr.Textbox(label=\"Your prompt\"),\n",
        "                        gr.Textbox(label=\"Negative prompt\"),\n",
        "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
        "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                                  info=\"Controls how much the text prompt influences the result\"),\n",
        "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
        "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
        "                    ],\n",
        "                    outputs=[gr.Image(label=\"Result\")],\n",
        "                    title=\"Image Generation with Stable Diffusion\",\n",
        "                    description=\"Generate any image with Stable Diffusion\",\n",
        "                    allow_flagging=\"never\"\n",
        "                    )\n",
        "\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT2']))"
      ],
      "metadata": {
        "id": "tQUZJfhsudPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()"
      ],
      "metadata": {
        "id": "pOunB6c0udMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `gr.Blocks()`\n",
        "\n",
        "- Within `gr.Blocks()`, you can define multiple `gr.Row()`s, or multiple `gr.Column()`s.\n",
        "- Note that if the jupyter notebook is very narrow, the layout may change to better display the objects.  If you define two columns but don't see the two columns in the app, try expanding the width of your web browser, and the screen containing this jupyter notebook.\n",
        "\n",
        "- When using `gr.Blocks()`, you'll need to explicitly define the \"Submit\" button using `gr.Button()`, whereas the 'Clear' and 'Submit' buttons are automatically added when using `gr.Interface()`."
      ],
      "metadata": {
        "id": "phaUjiRRvh_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
        "    prompt = gr.Textbox(label=\"Your prompt\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
        "            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                      info=\"In many steps will the denoiser denoise the image?\")\n",
        "            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                      info=\"Controls how much the text prompt influences the result\")\n",
        "            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
        "            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
        "            btn = gr.Button(\"Submit\")\n",
        "        with gr.Column():\n",
        "            output = gr.Image(label=\"Result\")\n",
        "\n",
        "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
        "gr.close_all()\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT3']))"
      ],
      "metadata": {
        "id": "jR9en2qrudIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.close()"
      ],
      "metadata": {
        "id": "NKjcc5X-uc_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### scale\n",
        "\n",
        "- To choose how much relative width to give to each column, set the `scale` parameter of each `gr.Column()`.  \n",
        "- If one column has `scale=4` and the second column has `scale=1`, then the first column takes up 4/5 of the total width, and the second column takes up 1/5 of the total width.\n",
        "\n",
        "#### gr.Accordion()\n",
        "- The `gr.Accordion()` can show/hide  the app options with a mouse click.\n",
        "- Set `open=True` to show the contents of the Accordion by default, or `False` to hide it by default."
      ],
      "metadata": {
        "id": "rre7RifnvtHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=4):\n",
        "            prompt = gr.Textbox(label=\"Your prompt\") #Give prompt some real estate\n",
        "        with gr.Column(scale=1, min_width=50):\n",
        "            btn = gr.Button(\"Submit\") #Submit button side by side!\n",
        "    with gr.Accordion(\"Advanced options\", open=False): #Let's hide the advanced options!\n",
        "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                      info=\"In many steps will the denoiser denoise the image?\")\n",
        "                    guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                      info=\"Controls how much the text prompt influences the result\")\n",
        "                with gr.Column():\n",
        "                    width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
        "                    height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
        "    output = gr.Image(label=\"Result\") #Move the output up too\n",
        "\n",
        "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
        "\n",
        "gr.close_all()\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT4']))"
      ],
      "metadata": {
        "id": "3IwdMv1bvp9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()"
      ],
      "metadata": {
        "id": "9T707WY-vp5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GIlz4u1pvp1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ERWx2-ypvptG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}