{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9zZ7+8ZN3BcwE+hN9FiIs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RkanGen/Machine-Learning/blob/main/image_captioning_using_Gradio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ** Image captioning app üñºÔ∏èüìù**"
      ],
      "metadata": {
        "id": "XSjaI3iKwwFQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAwdWvi7wcPp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import IPython.display\n",
        "from PIL import Image\n",
        "import base64\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "hf_api_key = os.environ['HF_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper functions\n",
        "import requests, json\n",
        "\n",
        "#Image-to-text endpoint\n",
        "def get_completion(inputs, parameters=None, ENDPOINT_URL=os.environ['HF_API_ITT_BASE']):\n",
        "    headers = {\n",
        "      \"Authorization\": f\"Bearer {hf_api_key}\",\n",
        "      \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    data = { \"inputs\": inputs }\n",
        "    if parameters is not None:\n",
        "        data.update({\"parameters\": parameters})\n",
        "    response = requests.request(\"POST\",\n",
        "                                ENDPOINT_URL,\n",
        "                                headers=headers,\n",
        "                                data=json.dumps(data))\n",
        "    return json.loads(response.content.decode(\"utf-8\"))"
      ],
      "metadata": {
        "id": "ZurpNyC-wq7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \" \"\n",
        "display(IPython.display.Image(url=image_url))\n",
        "get_completion(image_url)"
      ],
      "metadata": {
        "id": "gUPAzGJuwq3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gr.Image()\n",
        "- The `type` parameter is the format that the `fn` function expects to receive as its input.  If `type` is `numpy` or `pil`, `gr.Image()` will convert the uploaded file to this format before sending it to the `fn` function.\n",
        "- If `type` is `filepath`, `gr.Image()` will temporarily store the image and provide a string path to that image location as input to the `fn` function."
      ],
      "metadata": {
        "id": "z5P-5fyExZ8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def image_to_base64_str(pil_image):\n",
        "    byte_arr = io.BytesIO()\n",
        "    pil_image.save(byte_arr, format='PNG')\n",
        "    byte_arr = byte_arr.getvalue()\n",
        "    return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
        "\n",
        "def captioner(image):\n",
        "    base64_image = image_to_base64_str(image)\n",
        "    result = get_completion(base64_image)\n",
        "    return result[0]['generated_text']\n",
        "\n",
        "gr.close_all()\n",
        "demo = gr.Interface(fn=captioner,\n",
        "                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n",
        "                    outputs=[gr.Textbox(label=\"Caption\")],\n",
        "                    title=\"Image Captioning with BLIP\",\n",
        "                    description=\"Caption any image using the BLIP model\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"christmas_dog.jpeg\", \"bird_flight.jpeg\", \"cow.jpeg\"])\n",
        "\n",
        "demo.launch(share=True, server_port=int(os.environ['PORT1']))"
      ],
      "metadata": {
        "id": "VTPORVWfwqyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()"
      ],
      "metadata": {
        "id": "DLAt9wguwqvL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}