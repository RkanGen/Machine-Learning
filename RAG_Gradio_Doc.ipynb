{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8+ACvsxrTRVMqRGpj+VNY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RkanGen/Machine-Learning/blob/main/RAG_Gradio_Doc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFWIXNV-h5is"
      },
      "outputs": [],
      "source": [
        "%pip install langchain_community\n",
        "%pip install langchain_experimental\n",
        "%pip install langchain-openai\n",
        "%pip install langchainhub\n",
        "%pip install chromadb\n",
        "%pip install langchain\n",
        "%pip install beautifulsoup4\n",
        "%pip install python-dotenv\n",
        "\n",
        "# new\n",
        "%pip install gradio\n",
        "%pip uninstall uvloop -y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "import bs4\n",
        "import openai\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "import chromadb\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# new\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "asyncio.set_event_loop_policy(asyncio.DefaultEventLoopPolicy())\n",
        "nest_asyncio.apply()\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "8ADWLyN8h-cz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# variables\n",
        "_ = load_dotenv(dotenv_path='env.txt')\n",
        "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']\n",
        "embedding_function = OpenAIEmbeddings()\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\")\n",
        "str_output_parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "JS5wjeYoh-Q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Documents\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://kbourne.github.io/chapter1.html\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "6K4JUDBeh-C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split\n",
        "text_splitter = SemanticChunker(embedding_function)\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "xoaC4P30iHCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=embedding_function)\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "nktAkZNviG--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### RETRIEVAL and GENERATION ####\n",
        "# Prompt\n",
        "prompt = hub.pull(\"jclemens24/rag-prompt\")"
      ],
      "metadata": {
        "id": "VBNKuXI_iG7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relevance check prompt\n",
        "relevance_prompt_template = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Given the following question and retrieved context, determine if the context is relevant to the question.\n",
        "    Provide a score from 1 to 5, where 1 is not at all relevant and 5 is highly relevant.\n",
        "    Return ONLY the numeric score, without any additional text or explanation.\n",
        "\n",
        "    Question: {question}\n",
        "    Retrieved Context: {retrieved_context}\n",
        "\n",
        "    Relevance Score:\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "0bm_0gvkiG3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "VDWK21e0iGz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_score(llm_output):\n",
        "    try:\n",
        "        score = float(llm_output.strip())\n",
        "        return score\n",
        "    except ValueError:\n",
        "        return 0\n",
        "\n",
        "# Chain it all together with LangChain\n",
        "def conditional_answer(x):\n",
        "    relevance_score = extract_score(x['relevance_score'])\n",
        "    if relevance_score < 4:\n",
        "        return \"I don't know.\"\n",
        "    else:\n",
        "        return x['answer']"
      ],
      "metadata": {
        "id": "2yO2dMO_iGvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain_from_docs = (\n",
        "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
        "    | RunnableParallel(\n",
        "        {\"relevance_score\": (\n",
        "            RunnablePassthrough()\n",
        "            | (lambda x: relevance_prompt_template.format(question=x['question'], retrieved_context=x['context']))\n",
        "            | llm\n",
        "            | str_output_parser\n",
        "        ), \"answer\": (\n",
        "            RunnablePassthrough()\n",
        "            | prompt\n",
        "            | llm\n",
        "            | str_output_parser\n",
        "        )}\n",
        "    )\n",
        "    | RunnablePassthrough().assign(final_answer=conditional_answer)\n",
        ")"
      ],
      "metadata": {
        "id": "lUxQ-kYiiGqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain_with_source = RunnableParallel(\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        ").assign(answer=rag_chain_from_docs)"
      ],
      "metadata": {
        "id": "1Fj93xKCiGkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Question - run the chain\n",
        "result = rag_chain_with_source.invoke(\"What are the advantages of using RAG?\")\n",
        "relevance_score = result['answer']['relevance_score']\n",
        "final_answer = result['answer']['final_answer']\n",
        "\n",
        "print(f\"Relevance Score: {relevance_score}\")\n",
        "print(f\"Final Answer:\\n{final_answer}\")"
      ],
      "metadata": {
        "id": "mIPYtYzOiGY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "def process_question(question):\n",
        "    result = rag_chain_with_source.invoke(question)\n",
        "    relevance_score = result['answer']['relevance_score']\n",
        "    final_answer = result['answer']['final_answer']\n",
        "    sources = [doc.metadata['source'] for doc in result['context']]\n",
        "    source_list = \", \".join(sources)\n",
        "    return relevance_score, final_answer, source_list\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=process_question,\n",
        "    inputs=gr.Textbox(label=\"Enter your question\", value=\"What are the advantages of using RAG?\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Relevance Score\"),\n",
        "        gr.Textbox(label=\"Final Answer\"),\n",
        "        gr.Textbox(label=\"Sources\")\n",
        "    ],\n",
        "    title=\"RAG Question Answering\",\n",
        "    description=\"Enter a question and get the relevance score, final answer, and sources from RAG.\"\n",
        ")"
      ],
      "metadata": {
        "id": "O-GPpRZgifG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(share=True, debug=True) # without credentials"
      ],
      "metadata": {
        "id": "uA_LDMNwig_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(share=True, debug=True, auth=(\"admin\", \"pass1234\")) # with credentials"
      ],
      "metadata": {
        "id": "8Weg2rN_ig8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5oo-Kg9Fig5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ifdrNdcZig1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQVsWD7nigx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YdJ5Y_6PigoV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}